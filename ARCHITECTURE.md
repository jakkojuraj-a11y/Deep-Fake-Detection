# ğŸ—ï¸ Architecture & Design Decisions

## Why EfficientNet-B4?

We evaluated three leading architectures for deepfake detection:

| Criteria | EfficientNet-B4 âœ… | ResNet-50 | Xception |
|---|---|---|---|
| FaceForensics++ Accuracy | **~96%** | ~92% | ~95% |
| Parameters | **19M** | 25M | 23M |
| Inference Speed | Fast | Fastest | Medium |
| Compound Scaling | âœ… Yes | âŒ No | âŒ No |
| ImageNet Top-1 | **83.4%** | 76.1% | 79.0% |

**EfficientNet-B4 was chosen because it:**

1. **Compound Scaling** â€” Simultaneously scales depth, width, and resolution using a principled coefficient, unlike ResNet (depth-only) or Xception (width-only). This leads to better feature extraction from facial manipulation artifacts.

2. **Best Accuracy-to-Compute Ratio** â€” Achieves higher accuracy than Xception and ResNet with fewer parameters and FLOPs.

3. **Strong Transfer Learning** â€” The ImageNet-pretrained features transfer exceptionally well to face-forensics tasks because facial manipulation artifacts (texture inconsistencies, blending boundaries) are captured by mid-level features that EfficientNet learns efficiently.

4. **Production Viable** â€” 19M parameters fits comfortably in memory for both GPU and CPU inference, making it suitable for deployment.

---

## How Overfitting Is Handled

Deepfake detection is prone to overfitting because datasets are often small and models can memorize compression artifacts. We combat this with **six complementary strategies**:

### 1. Aggressive Data Augmentation
```
RandomHorizontalFlip(p=0.5)
RandomRotation(Â±15Â°)
ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)
RandomAffine(translate=5%)
GaussianBlur(kernel=3, sigma=0.1-2.0)
RandomErasing(p=0.1)
```
These force the model to learn semantic manipulation features rather than memorizing pixel patterns.

### 2. Dropout Regularization
- **0.5 dropout** before the first fully-connected layer
- **0.3 dropout** before the final classification layer
- Combined dropout probability prevents co-adaptation of neurons

### 3. Early Stopping (patience=5)
Training halts after 5 epochs without validation loss improvement, preventing the model from memorizing training data.

### 4. Learning Rate Scheduling
`ReduceLROnPlateau` with patience=3 and factor=0.5. When validation loss plateaus, the learning rate is halved to enable finer convergence.

### 5. L2 Weight Decay (1e-4)
AdamW optimizer applies L2 regularization to prevent weight magnitudes from growing too large.

### 6. Batch Normalization
Added after the hidden layer in the classification head to stabilize training and act as a mild regularizer.

---

## How to Scale This System

### Horizontal Scaling (More Users)

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Load       â”‚
                    â”‚  Balancer    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚            â”‚            â”‚
        â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”
        â”‚ Instance 1 â”‚ â”‚ Inst. 2 â”‚ â”‚ Inst. 3 â”‚
        â”‚ (GPU/CPU)  â”‚ â”‚ (GPU)   â”‚ â”‚ (GPU)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Containerize** with Docker (already provided)
2. **Deploy** on Kubernetes/ECS with auto-scaling
3. **GPU inference** with NVIDIA Triton or TorchServe for batch processing
4. **Async processing** â€” Use Celery + Redis for video analysis queues

### Vertical Scaling (Better Accuracy)

1. **Larger Models** â€” Upgrade to EfficientNet-B7 or EfficientNet-V2
2. **Ensemble Methods** â€” Combine multiple architectures (EfficientNet + Xception + ResNet)
3. **Attention Mechanisms** â€” Add SE blocks or attention modules to focus on manipulation regions
4. **Multi-task Learning** â€” Train to detect specific manipulation types alongside binary classification
5. **Temporal Analysis** â€” For video, add LSTM/Transformer layers to capture temporal inconsistencies

### Data Scaling

1. **More Datasets** â€” Combine FaceForensics++, Celeb-DF, and DFDC
2. **Cross-dataset Training** â€” Improves generalization to unseen manipulation techniques
3. **Hard Negative Mining** â€” Focus training on difficult-to-detect manipulations
4. **Synthetic Augmentation** â€” Use GANs to generate additional training samples

### Production Checklist

- [ ] Model versioning (MLflow / DVC)
- [ ] A/B testing for model updates
- [ ] Monitoring & alerting (prediction drift)
- [ ] API rate limiting
- [ ] Input validation & sanitization
- [ ] Logging & audit trail
- [ ] ONNX export for cross-platform deployment

---

## Pipeline Overview

```
Input (Image/Video)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frame Extract â”‚ â† (Video only: extract every Nth frame)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MTCNN Face   â”‚ â† Detect & crop face region
â”‚ Detection    â”‚   (fallback: center-crop)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preprocessingâ”‚ â† Resize 224Ã—224, normalize (ImageNet stats)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EfficientNet â”‚ â† Feature extraction (1792-dim)
â”‚ B4 Backbone  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classifier   â”‚ â† Dropout â†’ 512 â†’ ReLU â†’ BN â†’ Dropout â†’ 2
â”‚ Head         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
   REAL / FAKE
  (+ confidence)
```
